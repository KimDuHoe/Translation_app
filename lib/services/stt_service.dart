import 'dart:async';
import 'dart:math';
import 'package:flutter/foundation.dart';
import 'package:speech_to_text/speech_recognition_result.dart';
import 'package:speech_to_text/speech_to_text.dart';
import 'package:permission_handler/permission_handler.dart';
import '../models/subtitle_data.dart';

// STT ì„œë¹„ìŠ¤ êµ¬í˜„ (ê°•í™”ëœ ê°ì • ë¶„ì„ í¬í•¨)
class STTService extends ChangeNotifier {
  final SpeechToText _speechToText = SpeechToText();

  bool _isInitialized = false;
  bool _isListening = false;
  String _currentText = '';
  String _lastRecognizedText = '';
  double _confidence = 0.0;
  String _currentSpeaker = 'í™”ì1';
  int _speakerCount = 1;

  // ê°•í™”ëœ ìŒì„± ë¶„ì„ ê´€ë ¨ ë³€ìˆ˜ë“¤
  double _currentPitch = 150.0;
  double _currentVolume = 50.0;
  double _currentSpeechRate = 140.0;
  double _currentEnergy = 0.5;
  DateTime? _lastSpeechTime;
  Duration _pauseDuration = Duration.zero;

  // ê°ì • ë¶„ì„ íˆìŠ¤í† ë¦¬
  final List<String> _emotionHistory = [];
  String _currentEmotion = 'ì°¨ë¶„';
  double _emotionConfidence = 0.0;
  String _emotionPattern = 'ì•ˆì •ì ';

  final List<SubtitleData> _subtitles = [];
  final StreamController<SubtitleData> _subtitleController =
      StreamController<SubtitleData>.broadcast();

  // ê³ ê¸‰ ê¸°ëŠ¥ ì„¤ì •
  bool _advancedEmotionAnalysis = true;
  double _emotionSensitivity = 1.0;

  // Getters
  bool get isInitialized => _isInitialized;
  bool get isListening => _isListening;
  bool get isNotListening => !_isListening;
  String get currentText => _currentText;
  String get lastRecognizedText => _lastRecognizedText;
  double get confidence => _confidence;
  List<SubtitleData> get subtitles => List.unmodifiable(_subtitles);
  Stream<SubtitleData> get subtitleStream => _subtitleController.stream;
  String get currentSpeaker => _currentSpeaker;
  String get currentEmotion => _currentEmotion;
  double get emotionConfidence => _emotionConfidence;
  String get emotionPattern => _emotionPattern;

  // ìŒì„± íŠ¹ì§• Getters
  double get currentPitch => _currentPitch;
  double get currentVolume => _currentVolume;
  double get currentSpeechRate => _currentSpeechRate;
  double get currentEnergy => _currentEnergy;

  // ê³ ê¸‰ ê¸°ëŠ¥ Getters
  bool get advancedEmotionAnalysis => _advancedEmotionAnalysis;
  double get emotionSensitivity => _emotionSensitivity;

  // STT ì´ˆê¸°í™”
  Future<bool> initialize() async {
    try {
      bool hasPermission = await _requestMicrophonePermission();
      if (!hasPermission) {
        if (kDebugMode) print('ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.');
        return false;
      }

      _isInitialized = await _speechToText.initialize(
        onStatus: _onSpeechStatus,
        onError: _onSpeechError,
        debugLogging: kDebugMode,
      );

      if (_isInitialized) {
        if (kDebugMode) print('STT ì´ˆê¸°í™” ì„±ê³µ');
      } else {
        if (kDebugMode) print('STT ì´ˆê¸°í™” ì‹¤íŒ¨');
      }

      notifyListeners();
      return _isInitialized;
    } catch (e) {
      if (kDebugMode) print('STT ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: $e');
      return false;
    }
  }

  Future<bool> _requestMicrophonePermission() async {
    var status = await Permission.microphone.status;
    if (status.isDenied) {
      status = await Permission.microphone.request();
    }
    return status.isGranted;
  }

  // ìŒì„± ì¸ì‹ ì‹œì‘
  Future<void> startListening() async {
    if (!_isInitialized) {
      if (kDebugMode) print('STTê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
      return;
    }

    if (_isListening) {
      if (kDebugMode) print('ì´ë¯¸ ìŒì„± ì¸ì‹ ì¤‘ì…ë‹ˆë‹¤.');
      return;
    }

    try {
      await _speechToText.listen(
        onResult: _onSpeechResult,
        listenFor: const Duration(seconds: 30),
        pauseFor: const Duration(seconds: 3),
        partialResults: true,
        localeId: 'ko_KR',
        cancelOnError: false,
        listenMode: ListenMode.confirmation,
      );

      _isListening = true;
      _currentText = '';
      _lastSpeechTime = DateTime.now();
      notifyListeners();
      if (kDebugMode) print('ìŒì„± ì¸ì‹ ì‹œì‘');
    } catch (e) {
      if (kDebugMode) print('ìŒì„± ì¸ì‹ ì‹œì‘ ì¤‘ ì˜¤ë¥˜: $e');
    }
  }

  // ìŒì„± ì¸ì‹ ì¤‘ì§€
  Future<void> stopListening() async {
    if (!_isListening) return;

    try {
      await _speechToText.stop();
      _isListening = false;

      if (_currentText.isNotEmpty) {
        _addSubtitle(_currentText, isPartial: false);
      }

      notifyListeners();
      if (kDebugMode) print('ìŒì„± ì¸ì‹ ì¤‘ì§€');
    } catch (e) {
      if (kDebugMode) print('ìŒì„± ì¸ì‹ ì¤‘ì§€ ì¤‘ ì˜¤ë¥˜: $e');
    }
  }

  // ìŒì„± ì¸ì‹ ì·¨ì†Œ
  Future<void> cancelListening() async {
    if (!_isListening) return;

    try {
      await _speechToText.cancel();
      _isListening = false;
      _currentText = '';
      notifyListeners();
      if (kDebugMode) print('ìŒì„± ì¸ì‹ ì·¨ì†Œ');
    } catch (e) {
      if (kDebugMode) print('ìŒì„± ì¸ì‹ ì·¨ì†Œ ì¤‘ ì˜¤ë¥˜: $e');
    }
  }

  // ìŒì„± ì¸ì‹ ê²°ê³¼ ì²˜ë¦¬
  void _onSpeechResult(SpeechRecognitionResult result) {
    _currentText = result.recognizedWords;
    _confidence = result.confidence;

    // ìŒì„± íŠ¹ì§• ì¶”ì¶œ ë° ì—…ë°ì´íŠ¸
    _updateVoiceFeatures(result);

    if (kDebugMode) {
      print(
          'ì¸ì‹ëœ í…ìŠ¤íŠ¸: $_currentText (í™•ì‹ ë„: ${(_confidence * 100).toStringAsFixed(1)}%)');
    }

    if (result.finalResult) {
      _lastRecognizedText = _currentText;
      _addSubtitle(_currentText, isPartial: false);
      _detectSpeakerChange();
    } else {
      notifyListeners();
    }
  }

  // ìŒì„± íŠ¹ì§• ì¶”ì¶œ ë° ì—…ë°ì´íŠ¸
  void _updateVoiceFeatures(SpeechRecognitionResult result) {
    double textLength = _currentText.length.toDouble();
    double confidenceBoost = _confidence;

    // í”¼ì¹˜ ì¶”ì • (í…ìŠ¤íŠ¸ íŠ¹ì„± ê¸°ë°˜)
    if (_currentText.contains('?') ||
        _currentText.contains('ì–´?') ||
        _currentText.contains('ì •ë§?')) {
      _currentPitch = 200 + (confidenceBoost * 100);
    } else if (_currentText.contains('!') ||
        _currentText.contains('ì™€') ||
        _currentText.contains('ëŒ€ë°•')) {
      _currentPitch = 250 + (confidenceBoost * 150);
    } else {
      _currentPitch = 120 + (confidenceBoost * 60);
    }

    // ë³¼ë¥¨ ì¶”ì •
    if (_currentText.contains('!') ||
        _currentText.toUpperCase() == _currentText) {
      _currentVolume = 70 + (confidenceBoost * 20);
    } else {
      _currentVolume = 45 + (confidenceBoost * 15);
    }

    // ë§í•˜ê¸° ì†ë„ ì¶”ì •
    DateTime now = DateTime.now();
    if (_lastSpeechTime != null) {
      Duration elapsed = now.difference(_lastSpeechTime!);
      if (elapsed.inMilliseconds > 0) {
        _currentSpeechRate = (textLength / elapsed.inSeconds) * 60;
        _pauseDuration = elapsed;
      }
    }

    _currentEnergy = _confidence * (1.0 + (textLength / 100));
    _lastSpeechTime = now;
  }

  // ê°•í™”ëœ ê°ì • ë¶„ì„
  String _analyzeEmotion(String text) {
    if (!_advancedEmotionAnalysis) {
      return _analyzeEmotionSimple(text);
    }

    // ë©€í‹°ëª¨ë‹¬ ê°ì • ë¶„ì„
    Map<String, double> voiceScores = _analyzeVoiceFeatures();
    Map<String, double> textScores = _analyzeTextEmotion(text);
    Map<String, double> contextScores = _analyzeContext();

    // ê°€ì¤‘ì¹˜ ì ìš©í•˜ì—¬ ìµœì¢… ê°ì • ê²°ì •
    Map<String, double> finalScores =
        _combineScores(voiceScores, textScores, contextScores);

    String detectedEmotion = _getTopEmotion(finalScores);

    // ê°ì • íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
    _emotionHistory.insert(0, detectedEmotion);
    if (_emotionHistory.length > 10) {
      _emotionHistory.removeRange(10, _emotionHistory.length);
    }

    // ê°ì • íŒ¨í„´ ë¶„ì„
    _emotionPattern = _analyzeEmotionPattern();
    _emotionConfidence = _calculateEmotionConfidence(detectedEmotion);

    return detectedEmotion;
  }

  // ìŒì„± íŠ¹ì§• ê¸°ë°˜ ê°ì • ë¶„ì„
  Map<String, double> _analyzeVoiceFeatures() {
    Map<String, double> scores = {
      'ê¸°ì¨': 0.0,
      'ìŠ¬í””': 0.0,
      'í™”ë‚¨': 0.0,
      'ë†€ëŒ': 0.0,
      'ì°¨ë¶„': 0.0
    };

    // í”¼ì¹˜ ê¸°ë°˜ ë¶„ì„
    if (_currentPitch > 200) {
      scores['ê¸°ì¨'] = (scores['ê¸°ì¨']! + 0.3).clamp(0.0, 1.0);
      scores['ë†€ëŒ'] = (scores['ë†€ëŒ']! + 0.2).clamp(0.0, 1.0);
    } else if (_currentPitch < 120) {
      scores['ìŠ¬í””'] = (scores['ìŠ¬í””']! + 0.3).clamp(0.0, 1.0);
    }

    // ë³¼ë¥¨ ê¸°ë°˜ ë¶„ì„
    if (_currentVolume > 70) {
      scores['í™”ë‚¨'] = (scores['í™”ë‚¨']! + 0.2).clamp(0.0, 1.0);
      scores['ê¸°ì¨'] = (scores['ê¸°ì¨']! + 0.1).clamp(0.0, 1.0);
    } else if (_currentVolume < 45) {
      scores['ìŠ¬í””'] = (scores['ìŠ¬í””']! + 0.2).clamp(0.0, 1.0);
    }

    // ë§í•˜ê¸° ì†ë„ ê¸°ë°˜ ë¶„ì„
    if (_currentSpeechRate > 180) {
      scores['ê¸°ì¨'] = (scores['ê¸°ì¨']! + 0.2).clamp(0.0, 1.0);
      scores['í™”ë‚¨'] = (scores['í™”ë‚¨']! + 0.1).clamp(0.0, 1.0);
    } else if (_currentSpeechRate < 100) {
      scores['ìŠ¬í””'] = (scores['ìŠ¬í””']! + 0.2).clamp(0.0, 1.0);
    }

    // ì—ë„ˆì§€ ê¸°ë°˜ ë¶„ì„
    if (_currentEnergy > 0.7) {
      scores['ê¸°ì¨'] = (scores['ê¸°ì¨']! + 0.1).clamp(0.0, 1.0);
      scores['í™”ë‚¨'] = (scores['í™”ë‚¨']! + 0.1).clamp(0.0, 1.0);
    }

    // ì‹ ë¢°ë„ ê°€ì¤‘ì¹˜ ì ìš©
    scores.updateAll((key, value) => value * _confidence * _emotionSensitivity);

    return scores;
  }

  // í…ìŠ¤íŠ¸ ê¸°ë°˜ ê°ì • ë¶„ì„
  Map<String, double> _analyzeTextEmotion(String text) {
    Map<String, double> scores = {
      'ê¸°ì¨': 0.0,
      'ìŠ¬í””': 0.0,
      'í™”ë‚¨': 0.0,
      'ë†€ëŒ': 0.0,
      'ì°¨ë¶„': 0.0
    };

    // ê°ì •ë³„ í‚¤ì›Œë“œ ì‚¬ì „
    Map<String, List<String>> emotionKeywords = {
      'ê¸°ì¨': [
        'ì¢‹',
        'ê¸°ì¨',
        'í–‰ë³µ',
        'ì›ƒ',
        'ì¦ê±°',
        'ì‹ ë‚˜',
        'ìµœê³ ',
        'ì™„ì „',
        'ëŒ€ë°•',
        'ì¶•í•˜',
        'ê°ì‚¬',
        'ì‚¬ë‘',
        'ğŸ’•',
        'ğŸ˜„',
        'ğŸ‘'
      ],
      'ìŠ¬í””': [
        'ìŠ¬í”„',
        'ì•„ì‰¬',
        'ì•ˆíƒ€ê¹',
        'ìš°ìš¸',
        'í˜ë“¤',
        'ê´´ë¡œ',
        'ì•„í”„',
        'ëˆˆë¬¼',
        'ì ˆë§',
        'ì™¸ë¡œ',
        'ğŸ˜¢',
        'ğŸ˜­'
      ],
      'í™”ë‚¨': [
        'í™”ë‚˜',
        'ì§œì¦',
        'ì‹«',
        'ë¯¸ì›Œ',
        'ì—´ë°›',
        'ë¹¡ì³',
        'ë¶„ë…¸',
        'ì•…',
        '!!!',
        'ì§„ì§œ',
        'ğŸ˜¡',
        'ğŸ’¢'
      ],
      'ë†€ëŒ': [
        'ì–´?',
        'ì •ë§?',
        'ì™€!',
        'í—',
        'ëŒ€ë°•',
        'ì„¸ìƒì—',
        'ë†€ë¼',
        'ì–´ë–»ê²Œ',
        'ë¯¿ì„ ìˆ˜ ì—†',
        'ğŸ˜²',
        'ğŸ˜±'
      ],
      'ì°¨ë¶„': ['ê·¸ë ‡', 'ìŒ', 'ë„¤', 'ì•Œê² ', 'ì´í•´', 'ê´œì°®', 'ë³´í†µ', 'ê·¸ëƒ¥', 'ğŸ˜']
    };

    // ê°•ë„ ë¶€ì‚¬
    Map<String, double> intensityMultipliers = {
      'ë§¤ìš°': 1.5,
      'ì •ë§': 1.4,
      'ë„ˆë¬´': 1.3,
      'ì™„ì „': 1.3,
      'ì—„ì²­': 1.2,
      'ì¢€': 0.8,
      'ì¡°ê¸ˆ': 0.7,
      'ì•½ê°„': 0.6
    };

    text = text.toLowerCase();

    for (String emotion in emotionKeywords.keys) {
      double baseScore = 0.0;
      double intensityBonus = 1.0;

      // í‚¤ì›Œë“œ ë§¤ì¹­
      for (String keyword in emotionKeywords[emotion]!) {
        if (text.contains(keyword)) {
          baseScore += 0.2;
        }
      }

      // ê°•ë„ ë¶€ì‚¬ ë¶„ì„
      for (String intensifier in intensityMultipliers.keys) {
        if (text.contains(intensifier)) {
          intensityBonus =
              max(intensityBonus, intensityMultipliers[intensifier]!);
        }
      }

      // ë¶€ì •ë¬¸ ë¶„ì„
      if (text.contains('ì•ˆ ') || text.contains('ì•Š') || text.contains('ëª»')) {
        if (emotion == 'ê¸°ì¨') {
          baseScore = 0.0;
          scores['ìŠ¬í””'] = (scores['ìŠ¬í””']! + 0.3).clamp(0.0, 1.0);
        }
      }

      // ì˜ë¬¸ë¬¸ ë¶„ì„
      if (text.contains('?') || text.contains('ê¹Œ')) {
        if (emotion == 'ë†€ëŒ') {
          intensityBonus += 0.3;
        }
      }

      scores[emotion] =
          (baseScore * intensityBonus * _emotionSensitivity).clamp(0.0, 1.0);
    }

    return scores;
  }

  // ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
  Map<String, double> _analyzeContext() {
    Map<String, double> scores = {
      'ê¸°ì¨': 0.0,
      'ìŠ¬í””': 0.0,
      'í™”ë‚¨': 0.0,
      'ë†€ëŒ': 0.0,
      'ì°¨ë¶„': 0.0
    };

    // ë§ ì‚¬ì´ì˜ ë©ˆì¶¤ ë¶„ì„
    if (_pauseDuration.inMilliseconds > 2000) {
      scores['ìŠ¬í””'] = (scores['ìŠ¬í””']! + 0.2).clamp(0.0, 1.0);
      scores['ë†€ëŒ'] = (scores['ë†€ëŒ']! + 0.1).clamp(0.0, 1.0);
    } else if (_pauseDuration.inMilliseconds < 500) {
      scores['ê¸°ì¨'] = (scores['ê¸°ì¨']! + 0.1).clamp(0.0, 1.0);
      scores['í™”ë‚¨'] = (scores['í™”ë‚¨']! + 0.1).clamp(0.0, 1.0);
    }

    return scores;
  }

  // ì ìˆ˜ ê²°í•©
  Map<String, double> _combineScores(
    Map<String, double> voiceScores,
    Map<String, double> textScores,
    Map<String, double> contextScores,
  ) {
    Map<String, double> finalScores = {};

    const double voiceWeight = 0.4;
    const double textWeight = 0.4;
    const double contextWeight = 0.2;

    for (String emotion in voiceScores.keys) {
      finalScores[emotion] = (voiceScores[emotion]! * voiceWeight) +
          (textScores[emotion]! * textWeight) +
          (contextScores[emotion]! * contextWeight);
    }

    return finalScores;
  }

  // ìµœê³  ì ìˆ˜ ê°ì • ì„ íƒ
  String _getTopEmotion(Map<String, double> scores) {
    String topEmotion = 'ì°¨ë¶„';
    double maxScore = 0.0;

    for (String emotion in scores.keys) {
      if (scores[emotion]! > maxScore) {
        maxScore = scores[emotion]!;
        topEmotion = emotion;
      }
    }

    // ìµœì†Œ ì„ê³„ê°’ ê²€ì‚¬
    if (maxScore < 0.3) {
      return 'ì°¨ë¶„';
    }

    return topEmotion;
  }

  // ê°„ë‹¨í•œ ê°ì • ë¶„ì„ (ê¸°ì¡´ ë°©ì‹)
  String _analyzeEmotionSimple(String text) {
    if (text.contains('ì¢‹') ||
        text.contains('ê°ì‚¬') ||
        text.contains('ê¸°ì¨') ||
        text.contains('í–‰ë³µ')) {
      return 'ê¸°ì¨';
    } else if (text.contains('í™”ë‚˜') ||
        text.contains('ì§œì¦') ||
        text.contains('ì‹«') ||
        text.contains('!')) {
      return 'ì§œì¦';
    } else if (text.contains('ë†€ë') ||
        text.contains('ì–´?') ||
        text.contains('ì •ë§?') ||
        text.contains('ì™€!')) {
      return 'ë†€ëŒ';
    } else if (text.contains('ìŠ¬í”„') ||
        text.contains('ì•„ì‰½') ||
        text.contains('ì•ˆíƒ€ê¹')) {
      return 'ìŠ¬í””';
    } else {
      return 'ì°¨ë¶„';
    }
  }

  // ê°ì • íŒ¨í„´ ë¶„ì„
  String _analyzeEmotionPattern() {
    if (_emotionHistory.length < 3) return 'ì•ˆì •ì ';

    List<String> last3 = _emotionHistory.take(3).toList();

    if (last3.every((e) => e == last3.first)) {
      return 'ì§€ì†ì ';
    } else if (last3.contains('í™”ë‚¨') && last3.contains('ìŠ¬í””')) {
      return 'ë¶ˆì•ˆì •';
    } else if (last3.where((e) => e == 'ê¸°ì¨').length >= 2) {
      return 'ê¸ì •ì ';
    } else {
      return 'ë³€í™”ì ';
    }
  }

  // ê°ì • ì‹ ë¢°ë„ ê³„ì‚°
  double _calculateEmotionConfidence(String emotion) {
    double baseConfidence = _confidence;

    // ìµœê·¼ ê°ì • ì¼ê´€ì„± ë³´ë„ˆìŠ¤
    if (_emotionHistory.length >= 3) {
      int sameEmotionCount =
          _emotionHistory.take(3).where((e) => e == emotion).length;
      baseConfidence += (sameEmotionCount / 3.0) * 0.2;
    }

    // ìŒì„± íŠ¹ì§• ì‹ ë¢°ë„ ë³´ë„ˆìŠ¤
    if (_currentEnergy > 0.7) baseConfidence += 0.1;
    if (_currentVolume > 60) baseConfidence += 0.1;

    // ê°ì • ì‹ ë¢°ë„ ê³„ì‚°
    double calculateEmotionConfidence(String emotion) {
      double baseConfidence = _confidence;

      // ìµœê·¼ ê°ì • ì¼ê´€ì„± ë³´ë„ˆìŠ¤
      if (_emotionHistory.length >= 3) {
        int sameEmotionCount =
            _emotionHistory.take(3).where((e) => e == emotion).length;
        baseConfidence += (sameEmotionCount / 3.0) * 0.2;
      }

      // ìŒì„± íŠ¹ì§• ì‹ ë¢°ë„ ë³´ë„ˆìŠ¤
      if (_currentEnergy > 0.7) baseConfidence += 0.1;
      if (_currentVolume > 60) baseConfidence += 0.1;

      return baseConfidence.clamp(0.0, 1.0);
    }

    return baseConfidence.clamp(0.0, 1.0);
  }

  // ìë§‰ ì¶”ê°€
  void _addSubtitle(String text, {bool isPartial = false}) {
    if (text.trim().isEmpty) return;

    final now = DateTime.now();
    final timeString =
        '${now.hour.toString().padLeft(2, '0')}:${now.minute.toString().padLeft(2, '0')}';

    String emotion = _analyzeEmotion(text);
    _currentEmotion = emotion;

    final subtitle = SubtitleData(
      speaker: _currentSpeaker,
      text: text.trim(),
      emotion: emotion,
      time: timeString,
    );

    if (!isPartial) {
      _subtitles.add(subtitle);
      _subtitleController.add(subtitle);
    }

    notifyListeners();
  }

  // í™”ì ë³€í™” ê°ì§€
  void _detectSpeakerChange() {
    if (_subtitles.isNotEmpty) {
      if (_shouldChangeSpeaker()) {
        _switchToNextSpeaker();
      }
    }
  }

  bool _shouldChangeSpeaker() {
    // ê°ì • ë³€í™”ë„ í™”ì ë³€ê²½ì˜ ë‹¨ì„œê°€ ë  ìˆ˜ ìˆìŒ
    if (_emotionHistory.length >= 2) {
      String currentEmotion = _emotionHistory[0];
      String previousEmotion = _emotionHistory[1];

      if ((currentEmotion == 'í™”ë‚¨' && previousEmotion == 'ê¸°ì¨') ||
          (currentEmotion == 'ê¸°ì¨' && previousEmotion == 'ìŠ¬í””')) {
        return true;
      }
    }

    // ê¸´ ì¹¨ë¬µ í›„ì˜ ë°œí™”ëŠ” ìƒˆë¡œìš´ í™”ìì¼ ê°€ëŠ¥ì„±
    if (_pauseDuration.inSeconds > 5) {
      return true;
    }

    return false;
  }

  void _switchToNextSpeaker() {
    _speakerCount++;
    if (_speakerCount > 3) _speakerCount = 1;
    _currentSpeaker = 'í™”ì$_speakerCount';
  }

  // í™”ì ìˆ˜ë™ ë³€ê²½
  void changeSpeaker(String speaker) {
    _currentSpeaker = speaker;
    notifyListeners();
  }

  // ìŒì„± ì¸ì‹ ìƒíƒœ ë³€í™” ì²˜ë¦¬
  void _onSpeechStatus(String status) {
    if (kDebugMode) print('STT ìƒíƒœ: $status');

    switch (status) {
      case 'listening':
        _isListening = true;
        break;
      case 'notListening':
        _isListening = false;
        break;
      case 'done':
        _isListening = false;
        break;
    }

    notifyListeners();
  }

  // ìŒì„± ì¸ì‹ ì˜¤ë¥˜ ì²˜ë¦¬
  void _onSpeechError(dynamic error) {
    if (kDebugMode) print('STT ì˜¤ë¥˜: $error');
    _isListening = false;
    notifyListeners();
  }

  // ì‹¤ì‹œê°„ ê°ì • ëª¨ë‹ˆí„°ë§ ìŠ¤íŠ¸ë¦¼
  Stream<Map<String, dynamic>> get emotionStream async* {
    while (true) {
      await Future.delayed(const Duration(milliseconds: 500));
      yield {
        'emotion': _currentEmotion,
        'confidence': _emotionConfidence,
        'pattern': _emotionPattern,
        'voiceFeatures': {
          'pitch': _currentPitch,
          'volume': _currentVolume,
          'speechRate': _currentSpeechRate,
          'energy': _currentEnergy,
        }
      };
    }
  }

  // ê°ì • í†µê³„ ê°€ì ¸ì˜¤ê¸°
  Map<String, dynamic> getEmotionStatistics() {
    Map<String, int> emotionCounts = {};

    for (var subtitle in _subtitles) {
      emotionCounts[subtitle.emotion] =
          (emotionCounts[subtitle.emotion] ?? 0) + 1;
    }

    String dominantEmotion = 'ì°¨ë¶„';
    int maxCount = 0;
    for (var entry in emotionCounts.entries) {
      if (entry.value > maxCount) {
        maxCount = entry.value;
        dominantEmotion = entry.key;
      }
    }

    double emotionStability = _getEmotionStability();

    return {
      'emotionCounts': emotionCounts,
      'dominantEmotion': dominantEmotion,
      'emotionStability': emotionStability,
      'currentPattern': _emotionPattern,
      'totalUtterances': _subtitles.length,
    };
  }

  double _getEmotionStability() {
    if (_emotionHistory.length < 3) return 1.0;

    List<String> recent = _emotionHistory.take(5).toList();
    Set<String> uniqueEmotions = recent.toSet();

    return 1.0 - (uniqueEmotions.length / recent.length);
  }

  // ê°ì • ê¸°ë°˜ ì¶”ì²œ ê¸°ëŠ¥
  String getEmotionBasedRecommendation() {
    switch (_currentEmotion) {
      case 'ìŠ¬í””':
        return 'ì°¨ë¶„í•œ ìŒì•…ì„ ë“¤ì–´ë³´ì‹œê±°ë‚˜ ì ì‹œ íœ´ì‹ì„ ì·¨í•´ë³´ì„¸ìš”.';
      case 'í™”ë‚¨':
        return 'ì‹¬í˜¸í¡ì„ í•˜ê³  ì ì‹œ ëŒ€í™”ë¥¼ ë©ˆì¶°ë³´ì„¸ìš”.';
      case 'ê¸°ì¨':
        return 'ì¢‹ì€ ë¶„ìœ„ê¸°ë„¤ìš”! ì´ ê¸°ë¶„ì„ ìœ ì§€í•´ë³´ì„¸ìš”.';
      case 'ë†€ëŒ':
        return 'ë†€ë¼ìš´ ì†Œì‹ì´ ìˆì—ˆë‚˜ìš”? ì°¨ê·¼ì°¨ê·¼ ì •ë¦¬í•´ë³´ì„¸ìš”.';
      default:
        return 'ì•ˆì •ì ì¸ ëŒ€í™”ê°€ ì´ì–´ì§€ê³  ìˆìŠµë‹ˆë‹¤.';
    }
  }

  // ê³ ê¸‰ ê°ì • ë¶„ì„ í™œì„±í™”/ë¹„í™œì„±í™”
  void toggleAdvancedEmotionAnalysis() {
    _advancedEmotionAnalysis = !_advancedEmotionAnalysis;
    notifyListeners();
  }

  // ê°ì • ë¯¼ê°ë„ ì¡°ì •
  void setEmotionSensitivity(double sensitivity) {
    _emotionSensitivity = sensitivity.clamp(0.1, 2.0);
    notifyListeners();
  }

  // ìë§‰ ì €ì¥
  Future<void> saveSubtitles() async {
    if (kDebugMode) print('ìë§‰ ì €ì¥: ${_subtitles.length}ê°œ í•­ëª©');
  }

  // ìë§‰ ì‚­ì œ
  void clearSubtitles() {
    _subtitles.clear();
    _emotionHistory.clear();
    _currentEmotion = 'ì°¨ë¶„';
    _emotionConfidence = 0.0;
    _emotionPattern = 'ì•ˆì •ì ';
    notifyListeners();
  }

  @override
  void dispose() {
    _speechToText.stop();
    _subtitleController.close();
    super.dispose();
  }
}
